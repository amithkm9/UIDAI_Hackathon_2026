{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üáÆüá≥ UIDAI Aadhaar Insights - Data Exploration\n",
        "\n",
        "**Problem Statement**: Unlocking Societal Trends in Aadhaar Enrolment and Updates\n",
        "\n",
        "This notebook covers:\n",
        "1. Loading all datasets (Biometric, Demographic, Enrolment)\n",
        "2. Data cleaning and preparation\n",
        "3. Initial statistics and exploration\n",
        "4. First visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "from glob import glob\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Settings\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette('husl')\n",
        "\n",
        "# Paths\n",
        "BASE_PATH = Path('.')\n",
        "BIOMETRIC_PATH = BASE_PATH / 'api_data_aadhar_biometric'\n",
        "DEMOGRAPHIC_PATH = BASE_PATH / 'api_data_aadhar_demographic'\n",
        "ENROLMENT_PATH = BASE_PATH / 'api_data_aadhar_enrolment'\n",
        "\n",
        "print(\"‚úÖ Libraries loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load All Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_all_csvs(folder_path, dataset_name):\n",
        "    \"\"\"Load and combine all CSV files from a folder.\"\"\"\n",
        "    csv_files = sorted(glob(str(folder_path / '*.csv')))\n",
        "    print(f\"\\nüìÇ Loading {dataset_name}: Found {len(csv_files)} files\")\n",
        "    \n",
        "    dfs = []\n",
        "    for i, file in enumerate(csv_files):\n",
        "        print(f\"   Loading file {i+1}/{len(csv_files)}: {os.path.basename(file)}\")\n",
        "        df = pd.read_csv(file)\n",
        "        dfs.append(df)\n",
        "        \n",
        "    combined = pd.concat(dfs, ignore_index=True)\n",
        "    print(f\"   ‚úÖ Total rows: {len(combined):,}\")\n",
        "    return combined\n",
        "\n",
        "# Load all three datasets\n",
        "print(\"=\"*60)\n",
        "print(\"üöÄ LOADING AADHAAR DATASETS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "df_biometric = load_all_csvs(BIOMETRIC_PATH, \"Biometric\")\n",
        "df_demographic = load_all_csvs(DEMOGRAPHIC_PATH, \"Demographic\")\n",
        "df_enrolment = load_all_csvs(ENROLMENT_PATH, \"Enrolment\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"üìä TOTAL RECORDS LOADED: {len(df_biometric) + len(df_demographic) + len(df_enrolment):,}\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Explore Dataset Structures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick look at each dataset\n",
        "print(\"=\"*60)\n",
        "print(\"üìã BIOMETRIC DATASET\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Shape: {df_biometric.shape}\")\n",
        "print(f\"Columns: {list(df_biometric.columns)}\")\n",
        "print(\"\\nSample data:\")\n",
        "df_biometric.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"üìã DEMOGRAPHIC DATASET\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Shape: {df_demographic.shape}\")\n",
        "print(f\"Columns: {list(df_demographic.columns)}\")\n",
        "print(\"\\nSample data:\")\n",
        "df_demographic.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*60)\n",
        "print(\"üìã ENROLMENT DATASET\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Shape: {df_enrolment.shape}\")\n",
        "print(f\"Columns: {list(df_enrolment.columns)}\")\n",
        "print(\"\\nSample data:\")\n",
        "df_enrolment.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Data Cleaning & Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_dataset(df, name):\n",
        "    \"\"\"Clean and prepare dataset.\"\"\"\n",
        "    print(f\"\\nüßπ Cleaning {name} dataset...\")\n",
        "    \n",
        "    # Create a copy\n",
        "    df_clean = df.copy()\n",
        "    \n",
        "    # Convert date to datetime\n",
        "    df_clean['date'] = pd.to_datetime(df_clean['date'], format='%d-%m-%Y')\n",
        "    \n",
        "    # Add useful time columns\n",
        "    df_clean['day_of_week'] = df_clean['date'].dt.day_name()\n",
        "    df_clean['day_num'] = df_clean['date'].dt.dayofweek\n",
        "    df_clean['week'] = df_clean['date'].dt.isocalendar().week\n",
        "    df_clean['month'] = df_clean['date'].dt.month\n",
        "    \n",
        "    # Clean state names (standardize)\n",
        "    df_clean['state'] = df_clean['state'].str.strip().str.title()\n",
        "    df_clean['district'] = df_clean['district'].str.strip().str.title()\n",
        "    \n",
        "    # Convert pincode to string (preserve leading zeros)\n",
        "    df_clean['pincode'] = df_clean['pincode'].astype(str).str.zfill(6)\n",
        "    \n",
        "    print(f\"   ‚úÖ Cleaned {len(df_clean):,} rows\")\n",
        "    return df_clean\n",
        "\n",
        "# Clean all datasets\n",
        "df_biometric_clean = clean_dataset(df_biometric, \"Biometric\")\n",
        "df_demographic_clean = clean_dataset(df_demographic, \"Demographic\")\n",
        "df_enrolment_clean = clean_dataset(df_enrolment, \"Enrolment\")\n",
        "\n",
        "print(\"\\n‚úÖ All datasets cleaned!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add total counts for easier analysis\n",
        "\n",
        "# Biometric: bio_age_5_17 + bio_age_17_\n",
        "df_biometric_clean['total_bio'] = df_biometric_clean['bio_age_5_17'] + df_biometric_clean['bio_age_17_']\n",
        "\n",
        "# Demographic: demo_age_5_17 + demo_age_17_\n",
        "df_demographic_clean['total_demo'] = df_demographic_clean['demo_age_5_17'] + df_demographic_clean['demo_age_17_']\n",
        "\n",
        "# Enrolment: age_0_5 + age_5_17 + age_18_greater\n",
        "df_enrolment_clean['total_enrol'] = (df_enrolment_clean['age_0_5'] + \n",
        "                                      df_enrolment_clean['age_5_17'] + \n",
        "                                      df_enrolment_clean['age_18_greater'])\n",
        "\n",
        "print(\"‚úÖ Added total count columns\")\n",
        "print(f\"\\nBiometric total authentications: {df_biometric_clean['total_bio'].sum():,}\")\n",
        "print(f\"Demographic total updates: {df_demographic_clean['total_demo'].sum():,}\")\n",
        "print(f\"Enrolment total: {df_enrolment_clean['total_enrol'].sum():,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Basic Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Date range and geographic coverage\n",
        "print(\"=\"*60)\n",
        "print(\"üìÖ DATE RANGE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Biometric:   {df_biometric_clean['date'].min().date()} to {df_biometric_clean['date'].max().date()}\")\n",
        "print(f\"Demographic: {df_demographic_clean['date'].min().date()} to {df_demographic_clean['date'].max().date()}\")\n",
        "print(f\"Enrolment:   {df_enrolment_clean['date'].min().date()} to {df_enrolment_clean['date'].max().date()}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üó∫Ô∏è  GEOGRAPHIC COVERAGE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Unique States: {df_enrolment_clean['state'].nunique()}\")\n",
        "print(f\"Unique Districts: {df_enrolment_clean['district'].nunique()}\")\n",
        "print(f\"Unique Pincodes: {df_enrolment_clean['pincode'].nunique()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Top States & Districts Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Top 10 States by Enrolment\n",
        "top_states_enrol = (df_enrolment_clean\n",
        "                    .groupby('state')['total_enrol']\n",
        "                    .sum()\n",
        "                    .sort_values(ascending=False)\n",
        "                    .head(10))\n",
        "\n",
        "# Create visualization\n",
        "fig = px.bar(\n",
        "    x=top_states_enrol.values,\n",
        "    y=top_states_enrol.index,\n",
        "    orientation='h',\n",
        "    title='üèÜ Top 10 States by Aadhaar Enrolments',\n",
        "    labels={'x': 'Total Enrolments', 'y': 'State'},\n",
        "    color=top_states_enrol.values,\n",
        "    color_continuous_scale='Viridis'\n",
        ")\n",
        "fig.update_layout(height=500, showlegend=False, yaxis={'categoryorder':'total ascending'})\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Top 10 Districts by Enrolment\n",
        "top_districts = (df_enrolment_clean\n",
        "                 .groupby(['state', 'district'])['total_enrol']\n",
        "                 .sum()\n",
        "                 .sort_values(ascending=False)\n",
        "                 .head(10)\n",
        "                 .reset_index())\n",
        "\n",
        "top_districts['location'] = top_districts['district'] + ', ' + top_districts['state']\n",
        "\n",
        "fig = px.bar(\n",
        "    top_districts,\n",
        "    x='total_enrol',\n",
        "    y='location',\n",
        "    orientation='h',\n",
        "    title='üèÜ Top 10 Districts by Aadhaar Enrolments',\n",
        "    labels={'total_enrol': 'Total Enrolments', 'location': 'District'},\n",
        "    color='total_enrol',\n",
        "    color_continuous_scale='Plasma'\n",
        ")\n",
        "fig.update_layout(height=500, showlegend=False, yaxis={'categoryorder':'total ascending'})\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Time-based Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Daily trend for all three datasets\n",
        "daily_bio = df_biometric_clean.groupby('date')['total_bio'].sum().reset_index()\n",
        "daily_demo = df_demographic_clean.groupby('date')['total_demo'].sum().reset_index()\n",
        "daily_enrol = df_enrolment_clean.groupby('date')['total_enrol'].sum().reset_index()\n",
        "\n",
        "# Create subplot\n",
        "fig = make_subplots(rows=3, cols=1, \n",
        "                    subplot_titles=('üìä Daily Biometric Authentications',\n",
        "                                    'üìù Daily Demographic Updates',\n",
        "                                    'üìã Daily Enrolments'),\n",
        "                    vertical_spacing=0.1)\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=daily_bio['date'], y=daily_bio['total_bio'], \n",
        "               mode='lines+markers', name='Biometric', line=dict(color='#2ecc71')),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=daily_demo['date'], y=daily_demo['total_demo'],\n",
        "               mode='lines+markers', name='Demographic', line=dict(color='#3498db')),\n",
        "    row=2, col=1\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=daily_enrol['date'], y=daily_enrol['total_enrol'],\n",
        "               mode='lines+markers', name='Enrolment', line=dict(color='#e74c3c')),\n",
        "    row=3, col=1\n",
        ")\n",
        "\n",
        "fig.update_layout(height=800, title_text='üìÖ Daily Trends - All Aadhaar Activities', showlegend=False)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Day of Week Analysis\n",
        "dow_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "\n",
        "dow_enrol = (df_enrolment_clean\n",
        "             .groupby('day_of_week')['total_enrol']\n",
        "             .sum()\n",
        "             .reindex(dow_order))\n",
        "\n",
        "fig = px.bar(\n",
        "    x=dow_enrol.index,\n",
        "    y=dow_enrol.values,\n",
        "    title='üìÖ Enrolments by Day of Week',\n",
        "    labels={'x': 'Day', 'y': 'Total Enrolments'},\n",
        "    color=dow_enrol.values,\n",
        "    color_continuous_scale='RdYlGn'\n",
        ")\n",
        "fig.update_layout(showlegend=False)\n",
        "fig.show()\n",
        "\n",
        "print(\"\\nüîç Key Insight: Check which days have highest/lowest activity for resource planning\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Age Group Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Age distribution in Enrolments\n",
        "age_totals = {\n",
        "    'Age 0-5 (Infants)': df_enrolment_clean['age_0_5'].sum(),\n",
        "    'Age 5-17 (Children)': df_enrolment_clean['age_5_17'].sum(),\n",
        "    'Age 18+ (Adults)': df_enrolment_clean['age_18_greater'].sum()\n",
        "}\n",
        "\n",
        "fig = px.pie(\n",
        "    values=list(age_totals.values()),\n",
        "    names=list(age_totals.keys()),\n",
        "    title='üë• Enrolment Distribution by Age Group',\n",
        "    color_discrete_sequence=px.colors.qualitative.Set2,\n",
        "    hole=0.4\n",
        ")\n",
        "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
        "fig.show()\n",
        "\n",
        "print(\"\\nüìä Total by Age Group:\")\n",
        "for age, count in age_totals.items():\n",
        "    print(f\"   {age}: {count:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Age distribution by State (Top 10 states)\n",
        "top_10_states = top_states_enrol.index.tolist()\n",
        "\n",
        "state_age = (df_enrolment_clean[df_enrolment_clean['state'].isin(top_10_states)]\n",
        "             .groupby('state')[['age_0_5', 'age_5_17', 'age_18_greater']]\n",
        "             .sum()\n",
        "             .reset_index())\n",
        "\n",
        "fig = px.bar(\n",
        "    state_age,\n",
        "    x='state',\n",
        "    y=['age_0_5', 'age_5_17', 'age_18_greater'],\n",
        "    title='üë• Age Group Distribution by Top 10 States',\n",
        "    labels={'value': 'Count', 'state': 'State', 'variable': 'Age Group'},\n",
        "    barmode='group'\n",
        ")\n",
        "fig.update_layout(legend_title='Age Group')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Save Cleaned Data for Next Phases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create output directory\n",
        "OUTPUT_PATH = BASE_PATH / 'processed_data'\n",
        "OUTPUT_PATH.mkdir(exist_ok=True)\n",
        "\n",
        "# Save cleaned datasets as parquet (faster and smaller than CSV)\n",
        "df_biometric_clean.to_parquet(OUTPUT_PATH / 'biometric_clean.parquet', index=False)\n",
        "df_demographic_clean.to_parquet(OUTPUT_PATH / 'demographic_clean.parquet', index=False)\n",
        "df_enrolment_clean.to_parquet(OUTPUT_PATH / 'enrolment_clean.parquet', index=False)\n",
        "\n",
        "print(\"‚úÖ Cleaned datasets saved to 'processed_data/' folder\")\n",
        "print(f\"   üìÅ biometric_clean.parquet  ({len(df_biometric_clean):,} rows)\")\n",
        "print(f\"   üìÅ demographic_clean.parquet ({len(df_demographic_clean):,} rows)\")\n",
        "print(f\"   üìÅ enrolment_clean.parquet  ({len(df_enrolment_clean):,} rows)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Summary & Key Findings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create summary table\n",
        "summary = {\n",
        "    'Metric': [\n",
        "        'Total Records (All datasets)',\n",
        "        'Biometric Authentications',\n",
        "        'Demographic Updates', \n",
        "        'New Enrolments',\n",
        "        'Date Range',\n",
        "        'States Covered',\n",
        "        'Districts Covered',\n",
        "        'Pincodes Covered'\n",
        "    ],\n",
        "    'Value': [\n",
        "        f\"{len(df_biometric_clean) + len(df_demographic_clean) + len(df_enrolment_clean):,}\",\n",
        "        f\"{df_biometric_clean['total_bio'].sum():,}\",\n",
        "        f\"{df_demographic_clean['total_demo'].sum():,}\",\n",
        "        f\"{df_enrolment_clean['total_enrol'].sum():,}\",\n",
        "        f\"{df_enrolment_clean['date'].min().date()} to {df_enrolment_clean['date'].max().date()}\",\n",
        "        f\"{df_enrolment_clean['state'].nunique()}\",\n",
        "        f\"{df_enrolment_clean['district'].nunique()}\",\n",
        "        f\"{df_enrolment_clean['pincode'].nunique()}\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "summary_df = pd.DataFrame(summary)\n",
        "print(\"=\"*60)\n",
        "print(\"üìä PHASE 1 SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(summary_df.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ PHASE 1 COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(\"\"\"\n",
        "What we accomplished:\n",
        "‚úÖ Loaded all CSV files (~5M records)\n",
        "‚úÖ Cleaned and prepared data\n",
        "‚úÖ Added useful columns (day_of_week, totals, etc.)\n",
        "‚úÖ Created initial visualizations\n",
        "‚úÖ Saved cleaned data for next phases\n",
        "\n",
        "Next: Phase 2 - Deep Pattern Analysis\n",
        "- Temporal patterns (trends over time)\n",
        "- Geographic patterns (state/district analysis)\n",
        "- Anomaly detection\n",
        "- Correlation analysis\n",
        "\"\"\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
